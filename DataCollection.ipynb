{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f598357f",
   "metadata": {},
   "source": [
    "Extracting Data From Youtube Comments and Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d792debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitterscraper import query_tweets\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import twint\n",
    "import nest_asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714e9655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected parameter: since\n"
     ]
    }
   ],
   "source": [
    "# Extracting twitter data with Hashtag #tesla\n",
    "\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "consumer_key= '5cBtVQH2Rkie41WiiRELRAhS'\n",
    "consumer_secret= 'DXW5qpefh0TZ6pEd3YI9JzLyCCjvVZWpxjQvbxBraUCTWjl0r'\n",
    "access_token= '104342269-jH1m50EIUmb19hQu18h3WLSOVL3p2fF5Yfue5B1'\n",
    "access_token_secret= 'PYwpTCCQuDciGS6dDBvORvGmdqGZgrCyam1jdp1AsK3R'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "tweets = []\n",
    "\n",
    "count = 1\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search_tweets, q=\"#tesla\", count=20).items(20):\n",
    "\t\n",
    "\ttry: \n",
    "\t\tdata = [tweet.created_at, tweet.id, tweet.text, tweet.user._json['screen_name'], tweet.user._json['name'], tweet.user._json['created_at'], tweet.entities['urls']]\n",
    "\t\tdata = tuple(data)\n",
    "\t\ttweets.append(data)\n",
    "\n",
    "\texcept tweepy.TweepError as e:\n",
    "\t\tprint(e.reason)\n",
    "\t\tcontinue\n",
    "\n",
    "\texcept StopIteration:\n",
    "\t\tbreak\n",
    "\n",
    "df = pd.DataFrame(tweets, columns = ['created_at','tweet_id', 'tweet_text', 'screen_name', 'name', 'account_creation_date', 'urls'])\n",
    "\n",
    "werr=df.to_csv(path_or_buf = 'Tesla_twitter12.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173f560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting youtube Comments data from recent youtube videos on Tesla\n",
    "\n",
    "# YOutube comments\n",
    "from googleapiclient.discovery import build\n",
    "video_id='8dvpArGYufg'\n",
    "#video_id ='kbulCM90w8w'\n",
    "#--video_id = \"nc0eOHWb7x8\"\n",
    "#--video_id='RZKxNSG_scI'\n",
    "api_key = 'AIzaSyCWIHigA2pN3VX877wHzzasOmOzf5azx2s'\n",
    "\n",
    "# recursive function to get all replies in a comment thread\n",
    "def get_replies(comment_id, token):\n",
    "    replies_response = yt_object.comments().list(part = 'snippet', maxResults = 100, parentId = comment_id, pageToken = token).execute()\n",
    "\n",
    "    for reply in replies_response['items']:\n",
    "        all_comments.append(reply['snippet']['textDisplay'])\n",
    "\n",
    "    if replies_response.get(\"nextPageToken\"):\n",
    "        return get_replies(comment_id, replies_response['nextPageToken'])\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "# recursive function to get all comments\n",
    "def get_comments(youtube, video_id, next_view_token):\n",
    "    global all_comments\n",
    "\n",
    "    # check for token\n",
    "    if len(next_view_token.strip()) == 0:\n",
    "        all_comments = []\n",
    "\n",
    "    if next_view_token == '':\n",
    "        # get the initial response\n",
    "        comment_list = youtube.commentThreads().list(part = 'snippet', maxResults = 100, videoId = video_id, order = 'relevance').execute()\n",
    "    else:\n",
    "        # get the next page response\n",
    "        comment_list = youtube.commentThreads().list(part = 'snippet', maxResults = 100, videoId = video_id, order='relevance', pageToken=next_view_token).execute()\n",
    "    # loop through all top level comments\n",
    "    for comment in comment_list['items']:\n",
    "        # add comment to list\n",
    "        all_comments.append([comment['snippet']['topLevelComment']['snippet']['textDisplay']])\n",
    "        # get number of replies\n",
    "        reply_count = comment['snippet']['totalReplyCount']\n",
    "        all_replies = []\n",
    "        # if replies greater than 0\n",
    "        if reply_count > 0:\n",
    "            # get first 100 replies\n",
    "            replies_list = youtube.comments().list(part='snippet', maxResults=100, parentId=comment['id']).execute()\n",
    "            for reply in replies_list['items']:\n",
    "                # add reply to list\n",
    "                all_replies.append(reply['snippet']['textDisplay'])\n",
    "\n",
    "            # check for more replies\n",
    "            while \"nextPageToken\" in replies_list:\n",
    "                token_reply = replies_list['nextPageToken']\n",
    "                # get next set of 100 replies\n",
    "                replies_list = youtube.comments().list(part = 'snippet', maxResults = 100, parentId = comment['id'], pageToken = token_reply).execute()\n",
    "                for reply in replies_list['items']:\n",
    "                    # add reply to list\n",
    "                    all_replies.append(reply['snippet']['textDisplay'])\n",
    "\n",
    "        # add all replies to the comment\n",
    "        all_comments[-1].append(all_replies)\n",
    "\n",
    "    if \"nextPageToken\" in comment_list:\n",
    "        return get_comments(youtube, video_id, comment_list['nextPageToken'])\n",
    "    else:\n",
    "        return []\n",
    "        \n",
    "\n",
    "\n",
    "all_comments = []\n",
    "\n",
    "# build a youtube object using our api key\n",
    "yt_object = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# get all comments and replies\n",
    "comments = get_comments(yt_object, video_id, '')\n",
    "#print(all_comments)\n",
    "comm_csv=[]\n",
    "for comment, replies in all_comments:\n",
    "    comm_csv.append(comment)\n",
    "    if len(replies) > 0:\n",
    "        for reply in replies:\n",
    "            comm_csv.append(reply)\n",
    "            \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "wer=pd.DataFrame({'comments':comm_csv})\n",
    "wer.head()\n",
    "w=wer.to_csv('youtube_comments_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
